-----------------------------------------------------------
CHAPTER 7 - USING DOCKER TO SUPERCHARGE AUTOMATION
-----------------------------------------------------------

- Executing Simple Admin Tasks in a Container

    - Let's assume we have a handy Perl script to strip all whitespace from a file.

        $ cat sample.txt | perl -lpe 's/^\s*//'


    - The only problem is that we don't have Perl installed on our machine.  But, we can
        use Docker to circumvent the need to install it.

        1. Create a new folder

             $ mkdir -p ~/fod/ch07/simple-task && cd ~/fod/ch07/simple-task


        2. Create a sample file in the new folder

             # File: sample.txt

             1234567890
               This is some text
                another line of text
              more text
                  final line


        3. Now, we can run a container with Perl installed in it.  We use the slim version
             of the official Perl image.

           We map the current working directory on our host to /usr/src/app in the container,
             and set /usr/src/app to be the container's working directory.


             # Run Perl script on our files without installing Perl
             $ docker container run --rm -it \
                                    -v $(pwd):/usr/src/app \
                                    -w /usr/src/app \
                                    perl:slim sh -c "cat sample.txt | perl -lpe 's/^\s*//'"


    - Note that we could even use some older version of Perl if we needed to.  

        perl:some-old-version


    - On hosts that don't have Python 3 installed, we can use this same technique to run
        Python 3 scripts.

        python:3.7.4-alpine python stats.py sample.txt



- Using Test Containers

    - Typical Test Types:

        1. Unit Tests
             Assert the correctness and quality of an individual, isolated piece of the 
               overall application.  

        2. Integration Tests
             Makes sure that pieces that are closely related work together as expected.

        3. Stress and Load Tests
             Tests the behavior of the application when handling lots of current requests
               and large amounts of data.

        4. End-to-End Tests
             Simulate a real user working with the application.


    - The code or component under test is often called a SUT (System Under Test).

      Unit tests are tightly coupled to the actual code, so they live in the same container
        as the SUT.  Integration, stress/load, and end-to-end tests use the public interface
        of the application, so they often run from a separate container.


    - End-to-end tests often use the Selenium web driver to automate actions on a given web
        page.



- Integration Testing a Node.js Application - Preparing the Database

    1. Make a folder and subfolders for our application.  The subfolders are 'tests', 'api',
         and 'database'.

        $ mkdir ~/fod/ch07/integration-test-node && cd ~/fod/ch07/integration-test-node
        $ mkdir tests api database


    2. Create the script to initialize the database.  We will use it to create the Postgres
         database.

        # File: integration-test-node/database/init-script.sql

        CREATE TABLE hobbies(
           hobby_id serial PRIMARY KEY,
           hobby VARCHAR (255) UNIQUE NOT NULL
        );
        
        insert into hobbies(hobby) values('swimming');
        insert into hobbies(hobby) values('diving');
        insert into hobbies(hobby) values('jogging');
        insert into hobbies(hobby) values('dancing');
        insert into hobbies(hobby) values('cooking');


    3. Create a volume where the database will store it's files.

        $ docker volume create pg-data


    4. Run the database container.

        $ docker container run -d \
                               --name postgres \
                               -p 5432:5432 \
                               -v $(pwd)/database:/docker-entrypoint-initdb.d \
                               -v pg-data:/var/lib/postgresql/data \
                               -e POSTGRES_USER=dbuser \
                               -e POSTGRES_DB=sample-db \
                               postgres:11.5-alpine


    5. Verify that the new container is running.  We will see that the initialization
         script was run.

         $ docker container logs postgres

         ...
         server started
         CREATE DATABASE
         
         /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init-db.sql
         CREATE TABLE
         INSERT 0 1
         INSERT 0 1
         INSERT 0 1
         INSERT 0 1
         INSERT 0 1
         
         ...
         
         PostgreSQL init process complete; ready for start up.
         
         2019-09-07 17:22:30.056 UTC [1] LOG: listening on IPv4 address "0.0.0.0", port 5432
         ...



- Integration Testing a Node.js Application - Building the API

    1. Initialize the API project.

        $ cd api
        $ npm init


    2. Add a start command to the package.json.

        # File: package.json

        "scripts": {
          "start": "node index.js",
          "test": "echo \"Error: no test specified\" && exit 1"
        },


    3. Add Express JS.

        $ npm install express --save


    4. Create a 'server.js' file in the 'api' folder.

        # File: api/server.js

        const express = require('express');
        const app = express();

        app.listen(3000, '0.0.0.0', () => {
            console.log('Application listening at 0.0.0.0:3000');
        })

        app.get('/', (req, res) => {
            res.send('Sample API');
        })


    5. Start the app and test the home endpoint.

        # Start the app
        $ npm start

        # Test the home endpoint
        $ curl localhost:3000



- Integration Testing a Node.js Application - Testing the API

    1. Start the test project.

        $ cd tests
        $ npm init


    2. Install and initialize jasmine.

        # Install jasmine
        $ npm install --save-dev jasmine

        # Initialize jasmine for project
        $ node node_modules/jasmine/bin/jasmine init


    3. Now, create the config settings for the 'jasmine.json' file if one wasn't created
         automatically.

        # File: /spec/support/jasmine.json

        {
          "spec_dir": "spec",
          "spec_files": [
            "**/*[sS]pec.js"
          ],
          "stopSpecOnExpectationFailure": false,
          "random": false
        }


    4. Install the 'request' library so that we can make API calls to the SUT.

        $ npm install request --save-dev


    5. Add an 'api-spec.js' file to the 'spec' subfolder of the project.

        # File: tests/spec/api-spec.js

        var request = require("request");

        const base_url = process.env.BASE_URL || 'http://localhost:3000';

        describe("API test suite", () => {
            describe("GET /", () => {
                it("returns status code 200", function(done) {
                    request.get(base_url, (error, response, body) => {
                        expect(response.statusCode).toBe(200);
                        done();
                    });
                });
                it("returns description", function(done) {
                    request.get(base_url, (error, response, body) => {
                        expect(body).toBe("Sample API");
                        done();
                    });
                });
            });
        });


    6. Now, we have to edit the 'package.json' to change the test command to 'jasmine'.

        # File: package.json

        "scripts": {
            "test": "jasmine"
        },


    7. Now, we can run the tests and they should pass.

        $ npm test


    8. Now, to clean up, we can stop the api and remove the Postgres container.



- Integration Testing a Node.js Application - Run Everything in Containers

    1. First, we'll add a Dockerfile for the API.

        # File: api/Dockerfile

        FROM node:alpine
        WORKDIR /usr/src/app
        COPY package.json ./
        RUN npm install
        COPY . .
        EXPOSE 3000
        CMD npm start


    2. Next, add a Dockerfile for the tests.

        # File tests/Dockerfile

        FROM node:alpine
        WORKDIR /usr/src/app
        COPY package.json ./
        RUN npm install
        COPY . .
        CMD npm test


    3. Now, we're ready to run all 3 containers in the right sequence.  We'll create a 
         shell script to do it.

         # File: integration-test-node/test.sh

         docker image build -t api-node api
         docker image build -t tests-node tests
         
         docker network create test-net
         
         docker container run --rm -d \
             --name postgres \
             --net test-net \
             -v $(pwd)/database:/docker-entrypoint-initdb.d \
             -v pg-data:/var/lib/postgresql/data \
             -e POSTGRES_USER=dbuser \
             -e POSTGRES_DB=sample-db \
             postgres:11.5-alpine
         
         docker container run --rm -d \
             --name api \
             --net test-net \
             api-node
         
         echo "Sleeping for 5 sec..."
         sleep 5
         
         docker container run --rm -it \
             --name tests \
             --net test-net \
             -e BASE_URL="http://api:3000" \
             tests-node


    4. Make the script executable.

         $ chmod +x ./test.sh


    5. Now, we can run it.

         $ ./test.sh


    6. After running it, we can run a cleanup script.

         # File: integration-test-node/cleanup.sh
         docker container rm -f postgres api
         docker network rm test-net
         docker volume rm pg-data

         # Make script executable and run it
         $ chmod +x cleanup.sh
         $ ./test.sh



- The Testcontainers Project

    - Testcontainers is a useful project for Java developers.  

      It is a Java library that supports JUnit tests, throwaway instances of common 
        databases, Selenium web browsers, or anything else that can run in a Docker container.



- Using Docker to Power a CI/CD Pipeline - Jenkins Basics

    - In this example, we use Jenkins as our automation server to build a CI/CD pipeline.  
        Other automation servers such as TeamCity work equally well.  

      When using Jenkins, the central document is the 'Jenkinsfile', which will contain the
        definition of our pipeline with its multiple stages.


    - A simple Jenkinsfile with the 'Build', 'Test', 'Deploy to Staging', and 'Deploy to 
        Production' stages might look like this:

        # File: Jenkinsfile

        pipeline {
            agent any
            options {
                skipStagesAfterUnstable()
            }
            stages {
                stage('Build') {
                    steps {
                        echo 'Building'
                    }
                }
                stage('Test') {
                    steps {
                        echo 'Testing'
                    }
                }
                stage('Deploy to Staging') {
                    steps {
                        echo 'Deploying to Staging'
                    }
                }
                stage('Deploy to Production') {
                    steps {
                        echo 'Deploying to Production'
                    }
                }
            }
        }



- Using Docker to Power a CI/CD Pipeline - Creating the Pipeline

    1. First, we create a project folder named 'jenkins-pipeline' and navigate to it.  

         $ mkdir ~/fod/ch07/jenkins-pipeline && cd ~/fod/ch07/jenkins-pipeline


    2. Now, let's run Jenkins in a Docker container.

         $ docker run --rm -d \
                      --name jenkins \
                      -u root \
                      -p 8080:8080 \
                      -v jenkins-data:/var/jenkins_home \
                      -v /var/run/docker.sock:/var/run/docker.sock \
                      -v "$HOME":/home \
                      jenkinsci/blueocean

      Note that we are running as root inside the container and we are mounting the Docker
        socket into the container so that Jenkins can access Docker from within the container.

      Data produced and used by Jenkins will be stored in the Docker volume, 'jenkins-data'.


    3. Get the initial admin password automatically generated by Jenkins.

         $ docker container exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword

         90e41fc304bc48d19d4a7507c8d2dcf0


    4. In the web browser, navigate to http://localhost:8080 to access the graphical UI of 
         Jenkins.

       Unlock Jenkins with the admin password retrieved in the previous step.


    5. Next, choose 'Install Suggested Plugins' to have Jenkins install the most useful plugins.

       Then, create an admin user.

           u: admin
           p: admin123
           e: admin@admin.com

       Restart the server if prompted.


    6. Click 'New Item' > 'Pipeline' and create a new pipeline.

         Name: sample-pipeline

         Pipeline Tab > Script: Sample Jenkinsfile from above


    7. Now, click 'Build Now' for the new pipeline in the main Jenkins menu.



- Using Docker to Power a CI/CD Pipeline - Integrating the Sample Application

    1. Initialize our project folder as a Git project.

         $ cd jenkins-pipeline && git init


    2. Add a 'package.json' file to the folder.

         {
           "name": "jenkins-pipeline",
           "version": "1.0.0",
           "main": "server.js",
           "scripts": {
             "start": "node server.js",
             "test": "jasmine"
           },
           "dependencies": {
             "express": "^4.17.1"
           },
           "devDependencies": {
             "jasmine": "^3.4.0"
           }
         }


    3. Add a 'hobbies.js' file, which implements logic to retrieve hobbies as a JavaScript 
         modules called 'hobbies'.

         # File: hobbies.js

         const hobbies = ["jogging","cooking","diving","swimming","reading"];

         exports.getHobbies = () => {
             return hobbies;
         }
         
         exports.getHobby = id => {
             if(id<1 || id > hobbies.length)
                 return null;
             return hobbies[id-1];
         }