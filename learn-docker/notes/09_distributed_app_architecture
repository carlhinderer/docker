-----------------------------------------------------------
CHAPTER 9 - DISTRIBUTED APPLICATION ARCHITECTURE
-----------------------------------------------------------

- Understanding the Distributed Application Architecture

    - Defining the Terminology

        VM
          Virtual Machine

        Node
          Individual server used to run applications (can be physical or VM)

        Cluster
          Group of nodes connected by a network that are used to run distributed applications

        Network
          Physical and software-defined communication paths between individual nodes of a 
            cluster and programs running on those nodes

        Port
          Channel on which an application such as a web server listens for incoming requests

        Service
          Piece of software that implements a set of functionality used by other parts of the
            application (this is a very overloaded term)


    - Traditional monolithic applications have been written in such a way so that the result
        is one tightly-coupled program that runs on a named server somewhere in the data center.

      All of it's code is a single binary or a few tightly-coupled binaries.  

          Incoming Request  
                 |
                 v
          Server: blue-box-12a
          IP: 172.52.13.44                  
          Application: pet-shop
                 |
                 v
              Database



- Patterns and Best Practices

    - Loosely Coupled Components

        - It's much easier to develop a complex application if we divide it into smaller
            components.

        - Components should have well-defined public interfaces through which other components
            and the outside world can communicate with them.

        - For testing purposes, we will replace other components with stubs or mocks.


    - Stateful vs Stateless

        - A 'stateful' component is one that creates or modifies persistent data.  Typical
            examples are database services or services that create files.

        - 'Stateless' components do not create or modify persistent data.

        - Stateless components are much easier to handle.  They can be easily scaled up and down.
            They can be painlessly torn down and restarted in a different cluster.  For this
            reason, it is helpful to design a system in a way in which most components are
            stateless.


    - Service Discovery

        - Components that need to communicate with each other need to know the server and
            port where other services are located.  Traditionally this information would be 
            stored in a config file.

        - This approach will completely break down in a distributed environment.  We need an
            external authority to keep track of where things are.  Usually, DNS serves this
            purpose.


    - Routing

        - Routing is the mechanism for sending packets from a source component to a target
            component.

        - The OSI model layers 2, 3, 4, and 7 are relevant in the context of containers and
            container orchestration.


    - Load Balancing

        - Load balancing is used whenever a service is running on more than one instance.

        - We want to make sure each instance gets the same workload assigned to it.  There are 
            different algorithms for this, but round-robin is the most common.  

        - A load balancer also facilitates high availability if the load balancer periodically
            checks the health of each instance.


    - Defensive Programming

        - When developing a service for a distributed application, it is always important to
            remember that it is not standalone and depends on other services.  We need to deal
            with potential failures explicitly.

        - When a call to another service fails or times out, the calling code should be
            structured in such a way that the same call is repeated after a short wait time.  If
            the call fails again, we should wait a bit longer before trying again.  After a 
            certain amount of time, we should give up and provide a degraded service.

        - Important operations should always be logged in the proper category (debug, info, etc.).
            The logging information should be collected by a central log aggregation service and
            not be stored on an individual node of the cluster.

        - We should try to fail fast.  If unrecoverable errors are detected, we should have the
            service fail immediately and log meaningful information.  For instance, we should always
            validate input first before doing other things.   


    - Redundancy

        - A mission-critical system needs to be available at all times.  We should plan for
            when, not if, failures of individual nodes will occur.

        - To avoid downtime, each component of the system needs to be redundant.  This includes
            the application components and all infrastructure parts (like edge routers and load
            balancers).


    - Health Checks

        - To keep track of when components become unavailable, we poll each instance of the
            service to periodically check their health.

        - If the health check to a particular instance times out, we kill the corresponding
            instance and spin up a new instance in its place.  If all of this happens in a
            fully automated way, the system is auto-healing.

        - We could either have the proxy in charge of polling each instance, or we could make
            the instances responsible for sending periodic signals to the proxy.


    - Circuit Breaker Pattern

        - A circuit breaker is a mechanism used to avoid a distributed application going down
            due to the cascading failure of many essential components.  

        - We can achieve this by putting a circuit breaker in front of a service, which monitors
            for failures.  If the number of failures reaches a certain threshold, the circuit
            breaker will trip, and all subsequent calls will return with an error.



- Running in Production

    - Logging

        - Once a system is in production, we will not be able to live debug it.  Logs will be the
            only way to track down problems.  So, it is crucial that logging produces abundant
            and meaningful information.

        - In a distributed environment, the execution path of a single request can get very
            complex.  In order to trace things successfully, we need to include the time of the
            message, component, and node in every log message.

        - Logging information should be aggregated in a central location.


    - Tracing

        - Tracing is used to find out how an individual request is funneled through a distributed
            application and how much time is spend overall for the request and in each individual
            component.

        - This information can be used as one of the sources for dashboards that shows the behavior
            and health of the system.


    - Monitoring

        - Operations engineers like to have dashboards showing live key metrics of the system. 

        - These metrics can be non-functional, including:

            - Memory and CPU usage
            - Number of crashes or exceptions
            - Health of nodes

        - Functional (application-specific) metrics could be things like:

            - Number of orders completed
            - Items out of stock in an inventory service

        - Most often, the data used to aggregate numbers for a dashboard come from logs.  These could
            be system logs (non-functional) or application-level logs (functional).



- Application Updates

    - Rolling Updates

        - We first create one instance of the new updates, direct traffic to it, make sure it is 
            running correctly.  Then, we can start slowly replacing other instances.


    - Blue-green Deployments

        - In blue-green deployments, the current version of the application service, 'blue', handles
            all the application traffic.

        - We install the new version of the service, 'green', on the production system.  The new
            service is not wired with the rest of the application service yet.  

        - We smoke test the green service, and if tests pass, we'll start routing traffic to it and
            monitor it closely.


    - Canary Releases

        - We start the new version of the application, a small amount (~1%) of traffic is routed to
            it, then 5%, then more and more until fully deployed.


    - Irreversible Data Changes

        - If part of our process executes some universal change in our state, like a schema change in
            a relational dataabase, we need to use special care.  

        - We need 3 steps:

            1. Roll out a backward-compatible schema and data change.
            2. If successful, deploy the new code.
            3. If successful, clean up schema and remove backwards compatibility.


    - Rollback

        - Sooner or later, we will have a problem with one of our updates.  In this case, we need
            to roll back to recover from disaster.  So, we need to make sure we always have a 
            plan for how to roll back to the previous version.

        - With blue-green deployments, the rollback process should be fairly simple.  We can just
            switch the router back to the blue version.