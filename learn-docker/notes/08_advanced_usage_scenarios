-----------------------------------------------------------
CHAPTER 8 - ADVANCED DOCKER USAGE SCENARIOS
-----------------------------------------------------------

- Keeping Your Docker Environment Clean

    - First, we want to periodically delete any dangling images.  These are layers that
        have no relationship to any tagged images.  

        # Remove dangling images
        $ docker image prune -f


    - Stopped containers can waste precious resources also.  If we don't need them any more,
        we should remove them.

        # Remove all containers
        $ docker container prune --force


    - Unused Docker volumes can too quickly fill up disk space.  It's a good idea to clean
        them up also, especially in a development or CI environment where a lot of
        temporary volumes are created.

        # Remove all volumes not currently being used by any running containers
        $ docker volume prune



- Running Docker in Docker

    - At times, we may want to run a container hosting an application that automates
        certain Docker tasks.  

      The Docker engine and Docker CLI are installed on the host, but the application
        runs inside the container.  To allow applications inside the container to run 
        docker commands, we bind-mount Linux sockets from the host into the container.


    1. Create a 'builder' folder and navigate to it.

         $ mkdir builder && cd builder


    2. In this folder, create a Dockerfile.

         # File: Dockerfile

         FROM alpine:latest
         RUN apk update && apk add docker
         WORKDIR /usr/src/app
         COPY . .
         CMD ./pipeline.sh


    3. Now, create a 'pipeline.sh' file that automates the building, testing, and pushing
         of a Docker image.

         # File: pipeline.sh

         #! /bin/bash
         # *** Sample script to build, test and push containerized Node.js applications ***

         # build the Docker image
         docker image build -t $HUB_USER/$REPOSITORY:$TAG .

         # Run all unit tests
         docker container run $HUB_USER/$REPOSITORY:$TAG npm test

         # Login to Docker Hub
         docker login -u $HUB_USER -p $HUB_PWD

         # Push the image to Docker Hub
         docker image push $HUB_USER/$REPOSITORY:$TAG


    4. Make the script executable.

         $ chmod +x ./pipeline.sh


    5. Build the image.

         $ docker image build -t builder .


    6. Now, we want to try out our builder with a sample app, which we have located in the
         fod/ch08/sample-app folder.

         $ cd ~/fod/ch08/sample-app
         $ docker container run --rm \
             --name builder \
             -v /var/run/docker.sock:/var/run/docker.sock \
             -v "$PWD":/usr/src/app \
             -e HUB_USER=<user> \
             -e HUB_PWD=<password>@j \
             -e REPOSITORY=ch08-sample-app \
             -e TAG=1.0 \
             builder


       Note that we mount the Docker socket into the container with:

           -v /var/run/docker.sock:/var/run/docker.sock

       If everything goes well, there should be a container app built for the sample-app,
         the tests should have been run, and the image should have been pushed to Docker Hub.



- Formatting the Output of Common Docker Commands

    - Many Docker commands output a lot of information, which can make it hard to find
        the specific thing you're looking for.

      
    - Luckily, most commands accept a --format argument, which accepts a Go template.
        (This is because most of Docker is written in Go).  

        # Display only container name, image, and status
        $ docker container ps -a --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"



- Filtering the Output of Common Docker Commands

    - We can also filter the output of Docker commands.  The format of these is 
        '--filter key=<value>'.

        # Only return images with 'latest' tag that aren't dangling
        $ docker image ls --filter dangling=false --filter "reference=*/*/*:latest"



- Optimizing Your Build Processs

    - One mistake that many people make at first is running 'npm install' or some other
        expensive operation each time a subsequent layer (code files) is changed.

        FROM node:12.10-alpine
        WORKDIR /usr/src/app
        COPY . .
        RUN npm install
        CMD npm start


    - Instead, we want to run commands like 'npm install' above the layer that changes
        frequently.  First, we copy over only the 'package.json' file, which is all we need to
        run 'npm install', then run it, then copy over the rest of the project files.

        FROM node:12.10-alpine
        WORKDIR /usr/src/app
        COPY package.json ./
        RUN npm install
        COPY . .
        CMD npm start



- Limiting Resources Consumed by a Container

    - One of the great features of containers is the ability to limit the resources a
        single container can consume.  This includes CPU and memory consumption.

        # Limit the memory a container can use
        $ docker container run --rm -it \
                               --name stress-test \
                               --memory 512M \
                               ubuntu:19.04 /bin/bash


    - To test this, we can use the 'stress' tool, which we use to simulate memory pressure.

        # Install stress package
        $ apt-get update && apt-get install -y stress

        # View memory usage
        $ docker stats

        # Now, in another terminal, use memory
        $ stress -m 4



- Read-Only Filesystem

    - For security purposes, it is often advised to denine the filesystem or part of it 
        as read-only.  This makes the most sense for stateless services.

        # Run as read-only
        $ docker container run --tty -d \
                               --name billing \
                               --read-only \
                               alpine /bin/sh


        # Test it
        $ docker container exec -it billing \
                        sh -c 'echo "You are doomed!" > ./sample.txt'

        sh: can't create ./sample.txt: Read-only file system



- Avoid Running a Containerized Application as Root

    - Most applications do not need root access.  For instance, let's say we have some 
        secret content that only root users should be able to access.

      First, let's secure the file with 'chmod'.

        # Switch to root
        $ su -

        # Create secret file
        $ echo "You should not see this." >> top-secret.txt
        $ chmod 600 ./top-secret.txt

        # Switch back to regular user
        $ exit

        # Now, I cannot read the file
        $ cat ./top-secret.txt


    - Now, let's try to read the file from a container.

        # Create a Dockerfile
        FROM ubuntu:latest
        COPY ./top-secret.txt /secrets/
        CMD cat /secrets/top-secret.txt

        # Switch to root
        $ su -

        # Build the container (as root)
        $ docker image build -t demo-image .

        # Switch back to regular user
        $ exit

        # Now run the container (not as root)
        $ docker container run demo-image
        You should not see this.


    - Even though we are running the container from a regular account, the application running 
        inside the container automatically runs as root, so it has full access to protected
        resources.

      To fix this, we'll define an explicit user inside the container.

        FROM ubuntu:latest
        RUN groupadd -g 3000 demo-group |
            && useradd -r -u 4000 -g demo-group demo-user
        USER demo-user
        COPY ./top-secret.txt /secrets/
        CMD cat /secrets/top-secret.txt


      When we build the new image as root, then switch back to our regular user and run the 
        container, we will be blocked.

        # Build image
        $ su -
        $ docker image build -t demo-image .
        $ exit

        # Try to read file
        $ docker container run demo-image
        cat: /secrets/top-secret.txt: Permission denied



- Running Your Terminal in a Remote Container and Accessing it via HTTPS


- Running Your Development Environment Inside a Container


- Running Your Code Editor in a Remote Container and Accessing it via HTTPS