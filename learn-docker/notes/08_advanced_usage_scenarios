-----------------------------------------------------------
CHAPTER 8 - ADVANCED DOCKER USAGE SCENARIOS
-----------------------------------------------------------

- Keeping Your Docker Environment Clean

    - First, we want to periodically delete any dangling images.  These are layers that
        have no relationship to any tagged images.  

        # Remove dangling images
        $ docker image prune -f


    - Stopped containers can waste precious resources also.  If we don't need them any more,
        we should remove them.

        # Remove all containers
        $ docker container prune --force


    - Unused Docker volumes can too quickly fill up disk space.  It's a good idea to clean
        them up also, especially in a development or CI environment where a lot of
        temporary volumes are created.

        # Remove all volumes not currently being used by any running containers
        $ docker volume prune



- Running Docker in Docker

    - At times, we may want to run a container hosting an application that automates
        certain Docker tasks.  

      The Docker engine and Docker CLI are installed on the host, but the application
        runs inside the container.  To allow applications inside the container to run 
        docker commands, we bind-mount Linux sockets from the host into the container.


    1. Create a 'builder' folder and navigate to it.

         $ mkdir builder && cd builder


    2. In this folder, create a Dockerfile.

         # File: Dockerfile

         FROM alpine:latest
         RUN apk update && apk add docker
         WORKDIR /usr/src/app
         COPY . .
         CMD ./pipeline.sh


    3. Now, create a 'pipeline.sh' file that automates the building, testing, and pushing
         of a Docker image.

         # File: pipeline.sh

         #! /bin/bash
         # *** Sample script to build, test and push containerized Node.js applications ***

         # build the Docker image
         docker image build -t $HUB_USER/$REPOSITORY:$TAG .

         # Run all unit tests
         docker container run $HUB_USER/$REPOSITORY:$TAG npm test

         # Login to Docker Hub
         docker login -u $HUB_USER -p $HUB_PWD

         # Push the image to Docker Hub
         docker image push $HUB_USER/$REPOSITORY:$TAG


    4. Make the script executable.

         $ chmod +x ./pipeline.sh


    5. Build the image.

         $ docker image build -t builder .


    6. Now, we want to try out our builder with a sample app, which we have located in the
         fod/ch08/sample-app folder.

         $ cd ~/fod/ch08/sample-app
         $ docker container run --rm \
             --name builder \
             -v /var/run/docker.sock:/var/run/docker.sock \
             -v "$PWD":/usr/src/app \
             -e HUB_USER=<user> \
             -e HUB_PWD=<password>@j \
             -e REPOSITORY=ch08-sample-app \
             -e TAG=1.0 \
             builder


       Note that we mount the Docker socket into the container with:

           -v /var/run/docker.sock:/var/run/docker.sock

       If everything goes well, there should be a container app built for the sample-app,
         the tests should have been run, and the image should have been pushed to Docker Hub.



- Formatting the Output of Common Docker Commands

    - Many Docker commands output a lot of information, which can make it hard to find
        the specific thing you're looking for.

      
    - Luckily, most commands accept a --format argument, which accepts a Go template.
        (This is because most of Docker is written in Go).  

        # Display only container name, image, and status
        $ docker container ps -a --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"



- Filtering the Output of Common Docker Commands

    - We can also filter the output of Docker commands.  The format of these is 
        '--filter key=<value>'.

        # Only return images with 'latest' tag that aren't dangling
        $ docker image ls --filter dangling=false --filter "reference=*/*/*:latest"



- Optimizing Your Build Processs

    - One mistake that many people make at first is running 'npm install' or some other
        expensive operation each time a subsequent layer (code files) is changed.

        FROM node:12.10-alpine
        WORKDIR /usr/src/app
        COPY . .
        RUN npm install
        CMD npm start


    - Instead, we want to run commands like 'npm install' above the layer that changes
        frequently.  First, we copy over only the 'package.json' file, which is all we need to
        run 'npm install', then run it, then copy over the rest of the project files.

        FROM node:12.10-alpine
        WORKDIR /usr/src/app
        COPY package.json ./
        RUN npm install
        COPY . .
        CMD npm start



- Limiting Resources Consumed by a Container

    - One of the great features of containers is the ability to limit the resources a
        single container can consume.  This includes CPU and memory consumption.

        # Limit the memory a container can use
        $ docker container run --rm -it \
                               --name stress-test \
                               --memory 512M \
                               ubuntu:19.04 /bin/bash


    - To test this, we can use the 'stress' tool, which we use to simulate memory pressure.

        # Install stress package
        $ apt-get update && apt-get install -y stress

        # View memory usage
        $ docker stats

        # Now, in another terminal, use memory
        $ stress -m 4



- Read-Only Filesystem

- Avoid Running a Containerized Application as Root


- Running Your Terminal in a Remote Container and Accessing it via HTTPS


- Running Your Development Environment Inside a Container


- Running Your Code Editor in a Remote Container and Accessing it via HTTPS