---------------------------------------------------------------------
CHAPTER 1 - MAKING THE MOVE: DESIGN, PLAN, EXECUTE
---------------------------------------------------------------------

- The tools we will use include:

    1. Python
         To implement RESTful web services

    2. Git and Github
         To track and share changes

    3. Docker
         To use containers to standardize the operation of the microservices

    4. Kubernetes
         To coordinate the execution of multiple services

    5. Cloud Services (such as Travis CI and AWS)
         To leverage existing commercial solutions to problems



- We will also cover practices and techniques for working effectively in a 
    microservice-oriented environment:

    1. Continuous Integration
         To ensure that services are of a high quality and ready to be deployed

    2. GitOps
         For handling changes in infrastructure

    3. Observability
         For properly understanding what is happening in a live system

    4. Practices and techniques aimed at improving teamwork
         Within a single team and across multiple teams



- Web Services

    - A web service consists of:

        - 1 or more servers (physical boxes, VMs, cloud instances)

        - running a web server application (such as Nginx or Apache)

        - to direct requests directed to ports 80 or 443 toward 1 or more Python workers 
            (usually through the WSGI protocol) run by mod_wsgi (Apache), uWSGI, GNUnicorn, etc.


    - If more than one server is used, there will be a load balancer to spread the load among 
        them.  The server (or load balancer) needs to be accessible to the internet, so it
        needs to have a dedicated DNS and a public IP address.


    - Any other web framework will be similar: a frontend web server that exposes the HTTP/HTTPS
        ports, and a backend that runs the monolith in a dedicated web server.



- Liabilities of Monoliths

    1. The code will increase in size, and even with strict boundaries, developers will have a
         hard time understanding the entire code base.

    2. There is an inefficient use of resources, since each web worker will require enough 
         CPU/memory to handle any type of request.  Also, each worker may have it's own DB
         connection, even if infrequently used.

    3. There are issues with scaling the size of the development team, with more and more 
         people stepping on each others' toes.

    4. There are deployment limitations, since every concern will need to be shared across
         teams.  A deployment will bring down the entire system.

    5. There is an interdependency of technologies.  Updating dependencies can cause issues.
         Using a new type of technology is often impossible.

    6. A bug in a small part of the system can bring down the entire service.



- The Microservices Approach

    - A system with a 'microservices architecture' is a collection of loosely coupled
        specialized services that work in unison to provide a comprehensive service.

        1. Collection of specialized services
             There are different, well-defined modules

        2. Loosely coupled
             Each of the microservices can be independently deployed

        3. Work in unison
             Each microservice is capable of communicating with others

        4. Provide a comprehensive service
             Our microservice system will need to replicate the same functionality of the 
               monolith.



- Advantages of Microservices

    1. If communication is done with a standard protocol, each microservice can be programmed
         in different technologies.  HTTP requests with data encoded in JSON is the most
         standard and widely-used option.

    2. We have better resource utilization.  If one microservice requires more memory, we can
         reduce the number of worker copies.  We can decide which workers need to connect to
         the DB.

    3. Each individual service is smaller, which means it is easier to maintain, faster to add
         features, and more easy to understand.

    4. Some services can be hidden from external access.  This may improve the security of 
         sensitive data or services.

    5. Failure in one service does not necessarily mean the entire system won't be available.

    6. Each service can be developed, deployed, and maintained seprately by separate developers.



- Docker Containers

    - Docker containers are very often used to deploy microservices.  They are:

        1. Portable, since they are detached from the underlying platform and hardware

        2. Very lightweight, since a minimum amount of data needs to be included

        3. Secure, as the exposed attack surface of a container is relatively small


    - We should always remember to keep containers small and single-purpose.  If we end up adding
        several daemons and a lot of configuration, it probably needs to be split into several
        containers.

    - The 12-factor App Principles, a set of practices that have been proven successful in 
        developing web applications, are very aligned with Docker containers.

    - We should always remember that containers should be stateless.  Any state needs to be stored
        in a database, and each containers stores no persistent data.  This is one of the key
        elements for scalable web servers.

    - We use Docker for the individual microservices, and we use Kubernetes as the orchestrator
        that manages the whole cluster of services.



- Parallel Deployment and Development Speed

    - The single most important feature of microservices is the capacity to develop 
        independently.  Each service should be able to be developed, tested, and
        deployed separately from the other services.

    - Note that situations in which backwards compatibility is being broken is a time when
        strong coordination between teams is required.


    - The traditional way of dividing teams is to have an operations team that is in charge
        of infrastructure and any new deployments, since they are the only ones with access
        to the production servers.

      The microservices approach conflicts with this, since teams need control over their own
        deployments.  Kubernetes helps in this situation, since it decouples maintenance of
        infrastructure from deployment of services.



- Challenges and Red Flags

    - Systems get started as monoliths, since it is simpler and allows for quicker iteration.
        In any new company, which is pivoting and changing the code, and searching for a 
        successful business model, this is pivotal.

      However, once the system matures, the company grows.  The more developers that get 
        involved, the bigger the company gets, the more sense microservices make.


    - Moving to microservices has its own problems:

        1. Migrating to microservices requires a lot of effort, actively changes the way the
             organization operates, and will be a big investment until it starts to pay off.

        2. The switch requires cultural change, and people do not like change.  It forces
             clarification of interfaces and APIs, and this can cause particular discomfort.

        3. There is a learning curve in learning the tools and procedures.

        4. Debugging a request across services is more difficult than with a monolith.
             Reproducing bugs can be challenging.

        5. Splitting a monolith requires careful consideration.  A bad division line can cause
             services to be tightly coupled.

        6. There's an overhead in creating microservices, as there's some work that gets 
             replicated on each service.

        7. A balance has to be struck on how much freedom to give individual teams.  You want
             to avoid duplicated work and knowledge silos, but you want teams to be empowered
             and independent.

        8. In agile principles, working code is more important than comprehensive documentation.
             However, in microservices, it is important that APIs be well documented to reduce
             the amount of support between teams.  The best approach is to create self-documenting
             services.

        9. Each call to another service can increase the delay of responses.  This can produce
             latency problems.


    - Conway's Law

        Organizations that design systems are constrained to produce designs which are copies
          of the communications structures of the organization.



- Analyzing the Current System

    - The task of understanding the current system should never be underestimated.  It is likely
        that no single person has a good understanding of the entire system.  The effort
        involved will vastly depend on how structured the monolith.


    - Our example application is a micro-blogging site called 'MyThoughts'.

        Models:
          UserModel
          SessionModel
          ThoughtModel

        Urls:
          /login
          /logout
          /thoughts/new
          /thoughts
          /search
          /static 

        Views:
          login.py
          thoughts.py
          search.py

        Templates:
          login.html
          search.html
          list_thoughts.html
          base.html

        Static Assets:
          bootstrap.css


    - We can see some of the interdependencies:

        1. The static data is isolated. It can be changed without reqiring changes anywhere else.

        2. The search functionality is strongly related to the list of thoughts.  The template
             is similar, and the data is displayed the same way.

        3. Login and logout don't interact with ThoughtModel.  The edit the session, but the rest
             of the application only reads it.

        4. The base.html template generates the top bar, and it's used for all pages.



- Ideas For How to Proceed

    1. We could just leave it the way it is, and improve the things that need improving.


    2. Searching for thoughts is pretty basic.  At the moment, we directly search the database.
         If there are millions of thoughts, this won't be viable.  The code in 'search.py' could
         call a specific search microservice, backed by a search engine such as Solr or
         Elasticsearch.  This will scale the searches, and could add capabilites like search
         filters.

       Search is also read-only, so it may be a good idea to detach calls creating new thoughts
         from calls searching them.


    3. Authentication is also a different problem from reading and writing thoughts.  Splitting
         it will allow us to keep on track for new security issues and have a team specifically
         deal with those issues.

       The rest of the application just needs a check for whether a user is logged in or not.


    4. The frontend is pretty static.  Maybe we want to create a SPA using Angular or React.
         To do that, we need a RESTful API microservice that is able to return thoughts and
         searches.

       In this case, the new microservice will be the frontend, which will be served as static,
         precompiled code, and will pull from the backend.


    5. The RESTful API backend will also be available to allow external developers to create
         their own tools on top of the MyThoughts data, for example to build a native phone app.



- Potential Architecture

    We propose this potential architecture:

        Dynamic               static              Users Backend
        Frontend    <--->                       /
                              Proxy ----------- - Thoughts Backend
                                                \
                              HTML Frontend       Search Backend


        1. Users backend
             Responsible for all authentication tasks and keeping information about users

        2. Thoughts backend
             This will create and store thoughts.

        3. Search backend
             This will allow searching thoughts.

        4. Proxy
             Will route any request to the proper backend.  Must be externally accessible.

        5. HTML Frontend
             Will replicate any current functionality.  This will ensure that we work in a
               backwards-compatible way and can make the transition smoothly.

        6. Dynamic Frontend
             Allowing clients to access the backend will allow the creation of other clients
               than our HTML frontend.  A dynamic frontend server will be created, and there
               are talks with another company to create a mobile app.

        7. Static Assets
             A web server capable of handling static files.  This will serve the CSS and 
               Javascript files.



- Preparing and Adapting by Measuring Usage

    - To measure usage, we need 'observability', or the ability to know how a live system is
        working.  The main tools for this are metrics and logs.


    - If your application is a web service, it will have logs being created by default.  These 
        will have the URL, result, and time for each web request.  This can provide good 
        information about how much each URL is being called.



- Changes to Architecture

    1. The teams don't have a good knowledge of Angular or React, so we won't be creating a
         new frontend for the time being.

    2. The external mobile application will be created, so an externally accessible API is still
         desirable.

    3. After analyzing the logs, we see that search isn't used much, and it has to interact with
         the Thoughts backend, so we'll just keep search under the Thoughts backend.

    4. The Users backend has received well.

                                static          Users backend
                                               /
         Phone App    <---->    Proxy----------
                                               \
                                HTML frontend    Thoughts backend



- Strategic Planning to Break the Monolith

    - The 'strangler pattern' is used to replace parts of a system gradually until the old system
        is strangled and can be removed safely.


    - There are 3 different possibilities for doing this:

        1. Replace the older code with new code written from scratch for the new service.

        2. Divide the existing code up and split it into new services.

        3. Some combination of the 2.



- The Replacement Approach

    - Services are replaced in big chunks, only taking into account their external interfaces or
        effects.  Note that this is still done one part at a time, chunk by chunk.

    - Pros: You get to structure it however you want with the benefit of hindsight from the old
              system.  You don't inherit any technical debt.  You get to use whatever tools you
              want.  

    - Cons: This can be very expensive and take a long time.  For old services that are undocumented,
              this can be very difficult.  This approach can be taken if modules are stable, but
              trying to do it while active development is going on is near impossible.

    - This approach makes the most sense for old legacy systems that are small, especially if they
        are implemented in an old tech stack that is difficult to maintain.



- The Divide Approach

    - If the system is well-structured, maybe some parts of it can just be copy-pasted and
        wrapped in the minimal amount of code to allow it to be executed independently and
        interface with other systems.



- Change and Structured Approach

    - In this phase of the project, we should analyze these elements:

        1. An ordered plan of which microservices will be available first, taking the 
             dependencies into account.

        2. An idea of where the biggest pain points are, and whether working on them is a 
             priority.  Pain points are elements that are worked with frequently, but there is
             no easy way to deal with them.

        3. What are the difficult cases and cans of worms?  Acknowledge they exist and minimize
             their impact on other services.

        4. How can we get a couple quick wins to keep the momentum of the project going?

        5. What training do the existing employees need to work on the new services, and who
             do we need to hire to fill in any gaps?

        6. Are there team changes and who will own each new service?



- Our Resulting Plan

    - As a prerequisite, a load balancer will need to be in front of the operation.  This
        will be responsible for channeling requests to the proper microservice.


    - After that, static files will be served through their own independent service.  A
        static web server is enough, though it will be deployed as an independent 
        microservice.


    - The code for authentication will be replicated in a new service.  It will use a RESTful
        API to log in and generate a session, and to log out.  The service will be responsible
        for checking whether a user exists or not, as well as adding and removing them.

          1. The first idea was to check each session retrieved against the service, but since
               this is a very common operation, we will make a package that will be shared
               among all our externally faced microservices.  This package will allow
               checking to see whether a session has been generated with our own service.
               This will be achieved by signing the session cryptographically and sharing the
               secret across our services.  This makes the session one that does not need to
               be stored.

          2. The Users backend needs to be able to allow authentication using OAuth 2.0 schema,
               which will allow other external services not based on web browsers to 
               authenticate and operate (for example, a mobile app).


    - The Thoughts backend will also be replicated as a RESTful API.  


    - After both backends are available, the current monolith will be changed from calling the
        database directly to using the RESTful APIs of the backends.  After this is successfully
        done, the old deployment will be replace with a Docker build and added to the load
        balancer.


    - The new API will be added externally to the load balancer and promoted as externally
        accessible.

                                          / static
                                         /  Users Backend    --->  DB
           Client  <--->  LoadBalancer --   Thoughts Backend --->  
                                         \  HTML frontend
                                          \



- Technical Choices

    - Each of the microservices will be deployed in its own Docker container.  We will set
        up a Kubernetes cluster to orchestrate the different services.
    
    - The new backend services will be made in Flask using Flask-RESTPlus to generate a \
        RESTful app and connect to the existing database with SQLAlchemy.

    - The backend services will be served using the uWSGI server.

    - The static files will be served using NGINX.

    - NGINX will also be used as a load balancer to control the inputs.

    - HTML frontend will continue to use Django.



- Executing the Move

    - The final step is to actually execute the change.  This is the longest and most
        difficult part.  

    - The most important objective during this phase is backward compatibility.  The new
        system should behave exactly like the old system from an external point of view.



- The Load Balancer

    - A load balancer allows distributing HTTP requests among several backend resources.


    - The main operation of a load balancer is to allow traffic to be directed to a single
        address to be distributed among several identical backend servers that can spread 
        the load and achieve better throughput.

      Typically, the traffic is distributed through round-robin, but there are other options
        as well.


    - Load balancers allow rolling updates.  We can turn 1-2 servers off and update them, then
        test that they are working correctly.  After verification, we can stop sending requests
        to the old services, drain them, and turn them off, leaving only the new services.

      If we replace the workers 1 by 1 in this fashion, it is a 'rolling update'.


    - Any web server capable of acting in reverse proxy mode, such as NGINX, is capable of
        working as a load balancer.  

      HAProxy is the most complete option.  It specializes in working it situations with high
        availability and high demand.  It's very configurable and works with other protocols 
        besides just HTTP.

      Cloud providers like AWS or Google also offer load balancer products.



- Migrating to a Load Balancer

    1. Create a new DNS for your current system.  This will allow you to refer to it
         independently.

    2. Deploy your load balancer, configured to serve the traffic to your old system on
         the old DNS.  Create a DNS just for the load balancer so you can refer to it
         specifically.  

    3. Test that sending a request to the load balancer works the same way it worked 
         without the load balancer.

         # Send test request
         $ curl --header "Host:old-dns.com" http://loadbalancer/path

    4. Change the DNS to point to the load balancer IP.  Note that this takes time since
         caches are involved.  It might even take a day or two.

    5. The old IP is no longer in use.  The server can be removed from the external-facing
         network.


    - Note that because your load balancer is a single point of failure, you'll need to load
        balance your load balancer!

      The easiest way of doing it is creating several identical copies of HAProxy and adding
        a cloud provider load balancer on top.



- The Phases of Migration

     1. The Pilot Phase

     2. The Consolidation Phase

     3. The Final Phase